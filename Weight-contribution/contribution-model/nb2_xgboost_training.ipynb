{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: XGBoost Training & Comparison\n",
    "Trains XGBoost on each descriptor CSV from Notebook 1.\n",
    "Compares R2, MAE, RMSE across all scenarios.\n",
    "\n",
    "**CSV naming convention:**\n",
    "- `desc_{TYPE}_w{WINDOW}.csv` for individual types per window\n",
    "- `desc_ALL_w{WINDOW}.csv` for all types combined per window\n",
    "- `desc_ALL_multiwindow.csv` for all types across all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 CSV files:\n",
      "  desc_ALL_multiwindow.csv: 99 rows, 54 features\n",
      "  desc_ALL_w005.csv: 99 rows, 18 features\n",
      "  desc_ALL_w01.csv: 99 rows, 18 features\n",
      "  desc_ALL_w05.csv: 99 rows, 18 features\n",
      "  desc_A_w005.csv: 99 rows, 2 features\n",
      "  desc_A_w01.csv: 99 rows, 2 features\n",
      "  desc_A_w05.csv: 99 rows, 2 features\n",
      "  desc_B_w005.csv: 99 rows, 2 features\n",
      "  desc_B_w01.csv: 99 rows, 2 features\n",
      "  desc_B_w05.csv: 99 rows, 2 features\n",
      "  desc_C_w005.csv: 99 rows, 4 features\n",
      "  desc_C_w01.csv: 99 rows, 4 features\n",
      "  desc_C_w05.csv: 99 rows, 4 features\n",
      "  desc_D_w005.csv: 99 rows, 4 features\n",
      "  desc_D_w01.csv: 99 rows, 4 features\n",
      "  desc_D_w05.csv: 99 rows, 4 features\n",
      "  desc_E_w005.csv: 99 rows, 2 features\n",
      "  desc_E_w01.csv: 99 rows, 2 features\n",
      "  desc_E_w05.csv: 99 rows, 2 features\n",
      "  desc_F_w005.csv: 99 rows, 4 features\n",
      "  desc_F_w01.csv: 99 rows, 4 features\n",
      "  desc_F_w05.csv: 99 rows, 4 features\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "BASE_DIR = r\"C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\"\n",
    "CSV_DIR = os.path.join(BASE_DIR, \"Weight-contribution\", \"contribution-model\")\n",
    "\n",
    "# Find all descriptor CSVs\n",
    "csv_files = sorted(glob.glob(os.path.join(CSV_DIR, \"desc_*.csv\")))\n",
    "print(f\"Found {len(csv_files)} CSV files:\")\n",
    "for f in csv_files:\n",
    "    name = os.path.basename(f)\n",
    "    df_tmp = pd.read_csv(f)\n",
    "    feat_cols = [c for c in df_tmp.columns if c not in \n",
    "                 ['uid','Formula','alpha_R','heavy1_el','heavy2_el','heavy1_mass',\n",
    "                  'heavy2_mass','n_elements','window']]\n",
    "    print(f\"  {name}: {len(df_tmp)} rows, {len(feat_cols)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "# Columns to exclude from features\n",
    "NON_FEATURE_COLS = {'uid', 'Formula', 'alpha_R', 'heavy1_el', 'heavy2_el',\n",
    "                     'heavy1_mass', 'heavy2_mass', 'n_elements', 'window'}\n",
    "\n",
    "def train_and_evaluate(csv_path, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train XGBoost on a descriptor CSV.\n",
    "    Uses K-Fold CV (and LOO if n < 30).\n",
    "    Returns dict with metrics.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    csv_name = os.path.basename(csv_path)\n",
    "    \n",
    "    # Identify feature columns (numeric only, not metadata)\n",
    "    feature_cols = [c for c in df.columns if c not in NON_FEATURE_COLS]\n",
    "    # Keep only numeric\n",
    "    feature_cols = [c for c in feature_cols if df[c].dtype in ['float64','float32','int64','int32']]\n",
    "    \n",
    "    if len(feature_cols) == 0:\n",
    "        return {'csv': csv_name, 'error': 'no features'}\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['alpha_R'].values\n",
    "    n = len(y)\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    valid = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
    "    X, y = X[valid], y[valid]\n",
    "    n = len(y)\n",
    "    \n",
    "    if n < 10:\n",
    "        return {'csv': csv_name, 'error': f'too few samples ({n})'}\n",
    "    \n",
    "    # XGBoost with modest params for small dataset\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    results = {\n",
    "        'csv': csv_name,\n",
    "        'n_samples': n,\n",
    "        'n_features': len(feature_cols),\n",
    "        'features': feature_cols,\n",
    "    }\n",
    "    \n",
    "    # --- K-Fold CV ---\n",
    "    k = min(n_splits, n)\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    y_pred_kf = np.zeros(n)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        y_pred_kf[test_idx] = model.predict(X[test_idx])\n",
    "    \n",
    "    results['kfold_R2'] = r2_score(y, y_pred_kf)\n",
    "    results['kfold_MAE'] = mean_absolute_error(y, y_pred_kf)\n",
    "    results['kfold_RMSE'] = np.sqrt(mean_squared_error(y, y_pred_kf))\n",
    "    \n",
    "    # --- LOO CV (if small dataset) ---\n",
    "    if n <= 120:\n",
    "        loo = LeaveOneOut()\n",
    "        y_pred_loo = np.zeros(n)\n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            y_pred_loo[test_idx] = model.predict(X[test_idx])\n",
    "        \n",
    "        results['loo_R2'] = r2_score(y, y_pred_loo)\n",
    "        results['loo_MAE'] = mean_absolute_error(y, y_pred_loo)\n",
    "        results['loo_RMSE'] = np.sqrt(mean_squared_error(y, y_pred_loo))\n",
    "    else:\n",
    "        results['loo_R2'] = np.nan\n",
    "        results['loo_MAE'] = np.nan\n",
    "        results['loo_RMSE'] = np.nan\n",
    "    \n",
    "    # --- Feature importance (train on full data) ---\n",
    "    model.fit(X, y)\n",
    "    results['feature_importance'] = dict(zip(feature_cols, model.feature_importances_))\n",
    "    results['train_R2'] = r2_score(y, model.predict(X))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on desc_ALL_multiwindow.csv... "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier '.3f if isinstance(res.get('loo_R2'), float) else 'N/A'' for object of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSKIPPED: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKFold R2=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mkfold_R2\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, LOO R2=\u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloo_R2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mN/A\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.3f if isinstance(res.get(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloo_R2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m), float) else \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mN/A\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mn_samples\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, feats=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mn_features\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Invalid format specifier '.3f if isinstance(res.get('loo_R2'), float) else 'N/A'' for object of type 'float'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RUN ON ALL CSVs\n",
    "# ============================================================\n",
    "all_results = []\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    name = os.path.basename(csv_path)\n",
    "    print(f\"Training on {name}...\", end=\" \")\n",
    "    res = train_and_evaluate(csv_path)\n",
    "    all_results.append(res)\n",
    "    \n",
    "    if 'error' in res:\n",
    "        print(f\"SKIPPED: {res['error']}\")\n",
    "    else:\n",
    "        print(f\"KFold R2={res['kfold_R2']:.3f}, LOO R2={res.get('loo_R2', 'N/A'):.3f if isinstance(res.get('loo_R2'), float) else 'N/A'}, \"\n",
    "              f\"n={res['n_samples']}, feats={res['n_features']}\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESULTS SUMMARY TABLE\n",
    "# ============================================================\n",
    "summary_rows = []\n",
    "for res in all_results:\n",
    "    if 'error' in res:\n",
    "        continue\n",
    "    summary_rows.append({\n",
    "        'CSV': res['csv'],\n",
    "        'n': res['n_samples'],\n",
    "        'features': res['n_features'],\n",
    "        'train_R2': res['train_R2'],\n",
    "        'KFold_R2': res['kfold_R2'],\n",
    "        'KFold_MAE': res['kfold_MAE'],\n",
    "        'KFold_RMSE': res['kfold_RMSE'],\n",
    "        'LOO_R2': res.get('loo_R2', np.nan),\n",
    "        'LOO_MAE': res.get('loo_MAE', np.nan),\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary = df_summary.sort_values('KFold_R2', ascending=False)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"RESULTS RANKED BY KFold R2\")\n",
    "print(\"=\" * 100)\n",
    "print(df_summary.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Save\n",
    "summary_path = os.path.join(CSV_DIR, \"results_summary.csv\")\n",
    "df_summary.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSaved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION: R2 COMPARISON BAR CHART\n",
    "# ============================================================\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "df_plot = df_summary.sort_values('KFold_R2', ascending=True)\n",
    "y_pos = range(len(df_plot))\n",
    "\n",
    "bars = ax.barh(y_pos, df_plot['KFold_R2'], color='steelblue', alpha=0.8, label='KFold R2')\n",
    "if 'LOO_R2' in df_plot.columns:\n",
    "    ax.barh(y_pos, df_plot['LOO_R2'], color='coral', alpha=0.5, height=0.4, label='LOO R2')\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(df_plot['CSV'].str.replace('desc_', '').str.replace('.csv', ''), fontsize=8)\n",
    "ax.set_xlabel('R2 Score', fontsize=12)\n",
    "ax.set_title('XGBoost R2 by Descriptor Scenario', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=0.45, color='red', ls='--', lw=1, alpha=0.7, label='Previous best (0.45)')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CSV_DIR, 'r2_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE IMPORTANCE FOR BEST MODEL\n",
    "# ============================================================\n",
    "best_csv = df_summary.iloc[0]['CSV']\n",
    "best_res = [r for r in all_results if r.get('csv') == best_csv][0]\n",
    "\n",
    "print(f\"Best model: {best_csv}\")\n",
    "print(f\"KFold R2: {best_res['kfold_R2']:.3f}\")\n",
    "print(f\"LOO R2: {best_res.get('loo_R2', 'N/A')}\")\n",
    "print(f\"\\nFeature Importance:\")\n",
    "\n",
    "fi = best_res['feature_importance']\n",
    "fi_sorted = sorted(fi.items(), key=lambda x: x[1], reverse=True)\n",
    "for feat, imp in fi_sorted:\n",
    "    bar = '|' * int(imp * 50)\n",
    "    print(f\"  {feat:<25} {imp:.3f} {bar}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, max(4, len(fi_sorted)*0.4)))\n",
    "feats = [f[0] for f in fi_sorted]\n",
    "imps = [f[1] for f in fi_sorted]\n",
    "ax.barh(range(len(feats)), imps, color='steelblue')\n",
    "ax.set_yticks(range(len(feats)))\n",
    "ax.set_yticklabels(feats, fontsize=9)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title(f'Feature Importance: {best_csv}', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CSV_DIR, 'best_feature_importance.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PRED vs ACTUAL SCATTER FOR BEST MODEL\n",
    "# ============================================================\n",
    "best_path = os.path.join(CSV_DIR, best_csv)\n",
    "df_best = pd.read_csv(best_path)\n",
    "feat_cols = [c for c in df_best.columns if c not in NON_FEATURE_COLS \n",
    "             and df_best[c].dtype in ['float64','float32','int64','int32']]\n",
    "\n",
    "X = df_best[feat_cols].values\n",
    "y = df_best['alpha_R'].values\n",
    "valid = ~(np.isnan(X).any(axis=1) | np.isnan(y))\n",
    "X, y = X[valid], y[valid]\n",
    "\n",
    "# LOO predictions\n",
    "model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1,\n",
    "                     subsample=0.8, colsample_bytree=0.8,\n",
    "                     reg_alpha=1.0, reg_lambda=1.0, random_state=42, verbosity=0)\n",
    "\n",
    "y_pred = np.zeros(len(y))\n",
    "loo = LeaveOneOut()\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    y_pred[test_idx] = model.predict(X[test_idx])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(y, y_pred, alpha=0.6, edgecolors='black', linewidth=0.5, s=40)\n",
    "lims = [min(y.min(), y_pred.min()) - 0.2, max(y.max(), y_pred.max()) + 0.2]\n",
    "ax.plot(lims, lims, 'r--', lw=1.5, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual alpha_R (eV A)', fontsize=12)\n",
    "ax.set_ylabel('Predicted alpha_R (eV A)', fontsize=12)\n",
    "ax.set_title(f'LOO: {best_csv}\\nR2={r2_score(y,y_pred):.3f}, MAE={mean_absolute_error(y,y_pred):.3f}',\n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CSV_DIR, 'best_pred_vs_actual.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
