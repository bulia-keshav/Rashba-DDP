{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Descriptor Extraction\n",
    "Extracts orbital-weight-based descriptors from `vasprun.xml` for all Rashba compounds.\n",
    "\n",
    "**Descriptor Types:**\n",
    "- **A** `WM_total`: sum(w_X * M_X) at VBM/CBM\n",
    "- **B** `WM_p_only`: sum(p_X * M_X) using only p-orbital contributions\n",
    "- **C** `WM_p_frac`: p_i*M_i / sum(p_j*M_j) for top 2 heaviest elements\n",
    "- **D** `WM_indiv`: w_heavy1 * M_heavy1, w_heavy2 * M_heavy2 individually\n",
    "- **E** `p_frac`: total p-orbital fraction\n",
    "- **F** `p_heavy`: p_frac_of_heaviest * M_heaviest for top 2\n",
    "\n",
    "**Windows:** 0.05, 0.1, 0.5 eV\n",
    "\n",
    "**Target:** max(Rashba_parameter) per UID from rashba.csv\n",
    "\n",
    "**Output CSVs:** one per (type, window) combo + combined CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pymatgen.io.vasp.outputs import Vasprun\n",
    "from pymatgen.electronic_structure.core import Spin, OrbitalType\n",
    "from pymatgen.core.periodic_table import Element\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rashba CSV: C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\\Data\\rashba.csv\n",
      "Rashba compounds dir: C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\\Inverse-design\\rashba\n",
      "Output dir: C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\\Weight-contribution\\contribution-model\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PATHS - ADJUST THESE\n",
    "# ============================================================\n",
    "BASE_DIR = r\"C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\"\n",
    "RASHBA_CSV = os.path.join(BASE_DIR, \"Data\", \"rashba.csv\")\n",
    "RASHBA_DIR = os.path.join(BASE_DIR, \"Inverse-design\", \"rashba\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"Weight-contribution\", \"contribution-model\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Windows\n",
    "WINDOWS = [0.05, 0.1, 0.5, 1.0]\n",
    "\n",
    "print(f\"Rashba CSV: {RASHBA_CSV}\")\n",
    "print(f\"Rashba compounds dir: {RASHBA_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in rashba.csv: 205\n",
      "Unique UIDs: 99\n",
      "Columns: ['Formula', 'uid', 'spacegroup', 'ehull', 'bandgap', 'band', 'kpath', 'Rashba_parameter', 'SS', 'dE', 'anticrossing']\n",
      "\n",
      "Target: 99 compounds with max alpha_R\n",
      "            uid  alpha_R_max  Formula\n",
      "0  001e03f2c095        3.288     SSeW\n",
      "1  03bcf7dcdaf2        4.804   Sn2Te2\n",
      "2  04fdd7d1ec5c        1.018   ClSbTe\n",
      "3  05a06afa3b20        1.643  WMo3Se8\n",
      "4  0b7696e1f4c9        1.756  CrW3Se8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD RASHBA CSV & GET TARGET (max alpha_R per UID)\n",
    "# ============================================================\n",
    "df_rashba = pd.read_csv(RASHBA_CSV)\n",
    "print(f\"Total rows in rashba.csv: {len(df_rashba)}\")\n",
    "print(f\"Unique UIDs: {df_rashba['uid'].nunique()}\")\n",
    "print(f\"Columns: {list(df_rashba.columns)}\")\n",
    "\n",
    "# Max Rashba parameter per UID\n",
    "target = df_rashba.groupby('uid')['Rashba_parameter'].max().reset_index()\n",
    "target.columns = ['uid', 'alpha_R_max']\n",
    "\n",
    "# Also keep formula for reference\n",
    "uid_formula = df_rashba.groupby('uid')['Formula'].first().reset_index()\n",
    "target = target.merge(uid_formula, on='uid')\n",
    "\n",
    "print(f\"\\nTarget: {len(target)} compounds with max alpha_R\")\n",
    "print(target.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 compound directories with vasprun.xml\n",
      "Matched: 99/99\n",
      "\n",
      "Sample matches:\n",
      "  UID: 1dcd471c2288 -> AsBrS-1dcd471c2288\n",
      "    vasprun: ss_2d%2FAsBrS-1dcd471c2288%2Fbands_ncl%2Fvasprun.xml\n",
      "    exists: True\n",
      "  UID: 671e6de2497a -> AsBrTe-671e6de2497a\n",
      "    vasprun: ss_2d%2FAsBrTe-671e6de2497a%2Fbands_ncl%2Fvasprun.xml\n",
      "    exists: True\n",
      "  UID: 1a3be826b3e0 -> AsClSe-1a3be826b3e0\n",
      "    vasprun: ss_2d%2FAsClSe-1a3be826b3e0%2Fbands_ncl%2Fvasprun.xml\n",
      "    exists: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FIND VASPRUN FILES FOR EACH UID\n",
    "# ============================================================\n",
    "# Folder structure: rashba/AsBrTe-671e6de2497a/ss_2d%2FAsBrTe-671e6de2497a%2Fbands_ncl%2Fvasprun.xml\n",
    "# UID in CSV: 671e6de2497a (last part after dash)\n",
    "\n",
    "compound_dirs = {}\n",
    "for folder in os.listdir(RASHBA_DIR):\n",
    "    folder_path = os.path.join(RASHBA_DIR, folder)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    # Build expected vasprun path: ss_2d%2F{folder}%2Fbands_ncl%2Fvasprun.xml\n",
    "    vasprun_name = f\"ss_2d%2F{folder}%2Fbands_ncl%2Fvasprun.xml\"\n",
    "    vasprun_path = os.path.join(folder_path, vasprun_name)\n",
    "    \n",
    "    # Also try glob as fallback\n",
    "    if not os.path.exists(vasprun_path):\n",
    "        candidates = glob.glob(os.path.join(folder_path, \"*vasprun*\"))\n",
    "        if candidates:\n",
    "            vasprun_path = candidates[0]\n",
    "        else:\n",
    "            # Try recursive\n",
    "            candidates = glob.glob(os.path.join(folder_path, \"**\", \"vasprun.xml\"), recursive=True)\n",
    "            if candidates:\n",
    "                vasprun_path = candidates[0]\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # Extract UID: everything after the LAST dash\n",
    "    # e.g., AsBrTe-671e6de2497a -> 671e6de2497a\n",
    "    # e.g., Bi2P2S6-287dcf4f1a19 -> 287dcf4f1a19\n",
    "    last_dash = folder.rfind('-')\n",
    "    if last_dash >= 0:\n",
    "        uid_from_folder = folder[last_dash+1:]\n",
    "    else:\n",
    "        uid_from_folder = folder\n",
    "    \n",
    "    compound_dirs[uid_from_folder] = {\n",
    "        'folder': folder,\n",
    "        'vasprun': vasprun_path\n",
    "    }\n",
    "\n",
    "print(f\"Found {len(compound_dirs)} compound directories with vasprun.xml\")\n",
    "\n",
    "# Match with target UIDs from CSV\n",
    "matched = 0\n",
    "unmatched_uids = []\n",
    "for _, row in target.iterrows():\n",
    "    uid = row['uid']\n",
    "    # Try direct match\n",
    "    if uid in compound_dirs:\n",
    "        matched += 1\n",
    "        continue\n",
    "    # Try: CSV uid might be longer/shorter than folder uid\n",
    "    # e.g., CSV has 'da5fd2bb4' but folder has 'da5fd2bb4xxx' or vice versa\n",
    "    found = False\n",
    "    for folder_uid in list(compound_dirs.keys()):\n",
    "        if uid.startswith(folder_uid) or folder_uid.startswith(uid):\n",
    "            compound_dirs[uid] = compound_dirs[folder_uid]\n",
    "            matched += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        unmatched_uids.append((uid, row['Formula']))\n",
    "\n",
    "print(f\"Matched: {matched}/{len(target)}\")\n",
    "if unmatched_uids:\n",
    "    print(f\"\\nUnmatched ({len(unmatched_uids)}):\")\n",
    "    for uid, formula in unmatched_uids[:15]:\n",
    "        print(f\"  {formula} - {uid}\")\n",
    "\n",
    "# Show a few matches for sanity check\n",
    "print(f\"\\nSample matches:\")\n",
    "for i, (uid, info) in enumerate(list(compound_dirs.items())[:3]):\n",
    "    print(f\"  UID: {uid} -> {info['folder']}\")\n",
    "    print(f\"    vasprun: {os.path.basename(info['vasprun'])}\")\n",
    "    print(f\"    exists: {os.path.exists(info['vasprun'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CORE FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def get_dos_array(dos_obj):\n",
    "    \"\"\"Extract DOS values, summing spin channels for SOC.\"\"\"\n",
    "    if Spin.down in dos_obj.densities:\n",
    "        return dos_obj.densities[Spin.up] + dos_obj.densities[Spin.down]\n",
    "    return dos_obj.densities[Spin.up]\n",
    "\n",
    "def integrate_window(energies, dos_vals, window):\n",
    "    \"\"\"Integrate DOS in energy window using trapezoidal rule.\"\"\"\n",
    "    mask = (energies >= window[0]) & (energies <= window[1])\n",
    "    e_w = energies[mask]\n",
    "    d_w = dos_vals[mask]\n",
    "    if len(e_w) < 2:\n",
    "        return 0.0\n",
    "    return np.trapezoid(d_w, e_w)\n",
    "\n",
    "def extract_contributions(vasprun_path, window_size):\n",
    "    \"\"\"\n",
    "    Parse vasprun.xml and extract orbital/atomic contributions at VBM/CBM.\n",
    "    Returns dict with per-element per-orbital contributions (normalized).\n",
    "    \"\"\"\n",
    "    vr = Vasprun(vasprun_path, parse_dos=True, parse_eigen=False)\n",
    "    cdos = vr.complete_dos\n",
    "    e_fermi = vr.efermi\n",
    "    \n",
    "    vbm = cdos.get_cbm_vbm()[1]\n",
    "    cbm = cdos.get_cbm_vbm()[0]\n",
    "    \n",
    "    vbm_s = vbm - e_fermi\n",
    "    cbm_s = cbm - e_fermi\n",
    "    energies = cdos.energies - e_fermi\n",
    "    \n",
    "    vbm_win = [vbm_s - window_size, vbm_s]\n",
    "    cbm_win = [cbm_s, cbm_s + window_size]\n",
    "    \n",
    "    element_dos = cdos.get_element_dos()\n",
    "    orbital_map = {'s': OrbitalType.s, 'p': OrbitalType.p, 'd': OrbitalType.d}\n",
    "    \n",
    "    # Raw contributions\n",
    "    raw = {}\n",
    "    for element in element_dos:\n",
    "        el = str(element)\n",
    "        mass = Element(el).atomic_mass\n",
    "        Z = Element(el).Z\n",
    "        raw[el] = {'mass': float(mass), 'Z': Z}\n",
    "        \n",
    "        spd = cdos.get_element_spd_dos(element)\n",
    "        for orb_str in ['s', 'p', 'd']:\n",
    "            orb_type = orbital_map[orb_str]\n",
    "            if orb_type in spd:\n",
    "                dos_vals = get_dos_array(spd[orb_type])\n",
    "                raw[el][f'{orb_str}_VBM'] = integrate_window(energies, dos_vals, vbm_win)\n",
    "                raw[el][f'{orb_str}_CBM'] = integrate_window(energies, dos_vals, cbm_win)\n",
    "            else:\n",
    "                raw[el][f'{orb_str}_VBM'] = 0.0\n",
    "                raw[el][f'{orb_str}_CBM'] = 0.0\n",
    "    \n",
    "    # Total per band edge\n",
    "    total_vbm = sum(raw[el][f'{o}_VBM'] for el in raw for o in ['s','p','d'])\n",
    "    total_cbm = sum(raw[el][f'{o}_CBM'] for el in raw for o in ['s','p','d'])\n",
    "    \n",
    "    # Normalized\n",
    "    for el in raw:\n",
    "        for o in ['s','p','d']:\n",
    "            raw[el][f'{o}_VBM_norm'] = raw[el][f'{o}_VBM'] / total_vbm if total_vbm > 0 else 0\n",
    "            raw[el][f'{o}_CBM_norm'] = raw[el][f'{o}_CBM'] / total_cbm if total_cbm > 0 else 0\n",
    "        # Element-level (sum of orbitals)\n",
    "        raw[el]['w_VBM'] = sum(raw[el][f'{o}_VBM_norm'] for o in ['s','p','d'])\n",
    "        raw[el]['w_CBM'] = sum(raw[el][f'{o}_CBM_norm'] for o in ['s','p','d'])\n",
    "        # p-orbital fraction for this element\n",
    "        raw[el]['p_VBM'] = raw[el]['p_VBM_norm']\n",
    "        raw[el]['p_CBM'] = raw[el]['p_CBM_norm']\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def compute_descriptors(raw):\n",
    "    \"\"\"\n",
    "    From raw contributions dict, compute all descriptor types.\n",
    "    Returns flat dict of descriptors.\n",
    "    \"\"\"\n",
    "    desc = {}\n",
    "    elements = list(raw.keys())\n",
    "    \n",
    "    # Sort by mass (heaviest first)\n",
    "    sorted_els = sorted(elements, key=lambda x: raw[x]['mass'], reverse=True)\n",
    "    heavy1 = sorted_els[0] if len(sorted_els) >= 1 else None\n",
    "    heavy2 = sorted_els[1] if len(sorted_els) >= 2 else None\n",
    "    \n",
    "    # --- Type A: WM_total = sum(w_X * M_X) ---\n",
    "    desc['A_WM_VBM'] = sum(raw[el]['w_VBM'] * raw[el]['mass'] for el in elements)\n",
    "    desc['A_WM_CBM'] = sum(raw[el]['w_CBM'] * raw[el]['mass'] for el in elements)\n",
    "    \n",
    "    # --- Type B: WM_p_only = sum(p_X * M_X) ---\n",
    "    desc['B_WMp_VBM'] = sum(raw[el]['p_VBM'] * raw[el]['mass'] for el in elements)\n",
    "    desc['B_WMp_CBM'] = sum(raw[el]['p_CBM'] * raw[el]['mass'] for el in elements)\n",
    "    \n",
    "    # --- Type C: WM_p_frac = p_i*M_i / sum(p_j*M_j) for top 2 heaviest ---\n",
    "    denom_vbm = sum(raw[el]['p_VBM'] * raw[el]['mass'] for el in elements)\n",
    "    denom_cbm = sum(raw[el]['p_CBM'] * raw[el]['mass'] for el in elements)\n",
    "    \n",
    "    if heavy1:\n",
    "        desc['C_pfrac_h1_VBM'] = (raw[heavy1]['p_VBM'] * raw[heavy1]['mass']) / denom_vbm if denom_vbm > 0 else 0\n",
    "        desc['C_pfrac_h1_CBM'] = (raw[heavy1]['p_CBM'] * raw[heavy1]['mass']) / denom_cbm if denom_cbm > 0 else 0\n",
    "    else:\n",
    "        desc['C_pfrac_h1_VBM'] = 0\n",
    "        desc['C_pfrac_h1_CBM'] = 0\n",
    "    \n",
    "    if heavy2:\n",
    "        desc['C_pfrac_h2_VBM'] = (raw[heavy2]['p_VBM'] * raw[heavy2]['mass']) / denom_vbm if denom_vbm > 0 else 0\n",
    "        desc['C_pfrac_h2_CBM'] = (raw[heavy2]['p_CBM'] * raw[heavy2]['mass']) / denom_cbm if denom_cbm > 0 else 0\n",
    "    else:\n",
    "        desc['C_pfrac_h2_VBM'] = 0\n",
    "        desc['C_pfrac_h2_CBM'] = 0\n",
    "    \n",
    "    # --- Type D: WM_indiv = w_heavyN * M_heavyN ---\n",
    "    if heavy1:\n",
    "        desc['D_wm_h1_VBM'] = raw[heavy1]['w_VBM'] * raw[heavy1]['mass']\n",
    "        desc['D_wm_h1_CBM'] = raw[heavy1]['w_CBM'] * raw[heavy1]['mass']\n",
    "    else:\n",
    "        desc['D_wm_h1_VBM'] = 0\n",
    "        desc['D_wm_h1_CBM'] = 0\n",
    "    \n",
    "    if heavy2:\n",
    "        desc['D_wm_h2_VBM'] = raw[heavy2]['w_VBM'] * raw[heavy2]['mass']\n",
    "        desc['D_wm_h2_CBM'] = raw[heavy2]['w_CBM'] * raw[heavy2]['mass']\n",
    "    else:\n",
    "        desc['D_wm_h2_VBM'] = 0\n",
    "        desc['D_wm_h2_CBM'] = 0\n",
    "    \n",
    "    # --- Type E: p_frac = total p-orbital % ---\n",
    "    desc['E_pfrac_VBM'] = sum(raw[el]['p_VBM'] for el in elements)\n",
    "    desc['E_pfrac_CBM'] = sum(raw[el]['p_CBM'] for el in elements)\n",
    "    \n",
    "    # --- Type F: p_heavy = p_frac_of_heaviest * M_heaviest ---\n",
    "    if heavy1:\n",
    "        desc['F_ph1_VBM'] = raw[heavy1]['p_VBM'] * raw[heavy1]['mass']\n",
    "        desc['F_ph1_CBM'] = raw[heavy1]['p_CBM'] * raw[heavy1]['mass']\n",
    "    else:\n",
    "        desc['F_ph1_VBM'] = 0\n",
    "        desc['F_ph1_CBM'] = 0\n",
    "    \n",
    "    if heavy2:\n",
    "        desc['F_ph2_VBM'] = raw[heavy2]['p_VBM'] * raw[heavy2]['mass']\n",
    "        desc['F_ph2_CBM'] = raw[heavy2]['p_CBM'] * raw[heavy2]['mass']\n",
    "    else:\n",
    "        desc['F_ph2_VBM'] = 0\n",
    "        desc['F_ph2_CBM'] = 0\n",
    "    \n",
    "    # --- Metadata ---\n",
    "    desc['heavy1_el'] = heavy1 if heavy1 else 'NA'\n",
    "    desc['heavy2_el'] = heavy2 if heavy2 else 'NA'\n",
    "    desc['heavy1_mass'] = raw[heavy1]['mass'] if heavy1 else 0\n",
    "    desc['heavy2_mass'] = raw[heavy2]['mass'] if heavy2 else 0\n",
    "    desc['n_elements'] = len(elements)\n",
    "    \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/99] SSeW (001e03f2c095...) OK\n",
      "[2/99] Sn2Te2 (03bcf7dcdaf2...) OK\n",
      "[3/99] ClSbTe (04fdd7d1ec5c...) OK\n",
      "[4/99] WMo3Se8 (05a06afa3b20...) OK\n",
      "[5/99] CrW3Se8 (0b7696e1f4c9...) OK\n",
      "[6/99] ClSbSe (0c0fbdaf8f4a...) OK\n",
      "[7/99] ISbTe (0f02957b17cf...) OK\n",
      "[8/99] AsITe (114b3382699c...) OK\n",
      "[9/99] BiBrSe (11db0908d9ef...) OK\n",
      "[10/99] CrMo3Te8 (159f028a85d0...) OK\n",
      "[11/99] TiHf3Te8 (1667d1443160...) OK\n",
      "[12/99] Ti2Zr2Te8 (18e377cce57f...) OK\n",
      "[13/99] BrSbTe (18e62ba75259...) OK\n",
      "[14/99] HgTe (1a3bdd1b142a...) OK\n",
      "[15/99] AsClSe (1a3be826b3e0...) OK\n",
      "[16/99] AsBrS (1dcd471c2288...) OK\n",
      "[17/99] O2Pb2 (20f098bd3f31...) OK\n",
      "[18/99] GeSe (211bcb7f05d6...) OK\n",
      "[19/99] MoW3Se8 (24d6cc0a0fed...) OK\n",
      "[20/99] Bi2P2S6 (287dcf4f1a19...) OK\n",
      "[21/99] BiITe (2d41b3dd1772...) OK\n",
      "[22/99] MoSTe (2ea941c8bc3c...) OK\n",
      "[23/99] MoW3S8 (2f6f133abcc8...) OK\n",
      "[24/99] BiBrTe (304bc6a92d82...) OK\n",
      "[25/99] WMo3Te8 (323fb700d903...) OK\n",
      "[26/99] ISbSe (343d2125478e...) OK\n",
      "[27/99] Pb2Te6 (3995fa1bee6e...) OK\n",
      "[28/99] PbTe (3bc08d486d65...) OK\n",
      "[29/99] TiHf3Se8 (3e1923c616ad...) OK\n",
      "[30/99] MoCr3S8 (3fb52099b370...) OK\n",
      "[31/99] BiIS (40034665f9f1...) OK\n",
      "[32/99] BiISe (433f707c632c...) OK\n",
      "[33/99] Mo2W2S8 (449640ec4d30...) OK\n",
      "[34/99] BiBrS (49b7be14f786...) OK\n",
      "[35/99] ISSb (4c49d27e66e5...) OK\n",
      "[36/99] Ga2P2Te6 (4cb4ea247ef4...) OK\n",
      "[37/99] BrSSb (4da5c6be60db...) OK\n",
      "[38/99] TiZr3Te8 (4f1ab08988cc...) OK\n",
      "[39/99] AsClTe (4fd8ad708fb0...) OK\n",
      "[40/99] ZrTi3Se8 (52a5e2b280d4...) OK\n",
      "[41/99] Cr2W2Se8 (548aa830244c...) OK\n",
      "[42/99] Cr2W2S8 (5974b6403c31...) OK\n",
      "[43/99] ISSb (5b94060698bc...) OK\n",
      "[44/99] MoW3Te8 (5c3fe56a1a89...) OK\n",
      "[45/99] P2Sb2Se6 (5d1a32a28ffa...) OK\n",
      "[46/99] AsISe (5d829e480507...) OK\n",
      "[47/99] PbS (5e4ff1f56b4a...) OK\n",
      "[48/99] Cr2Mo2Se8 (60065d3bbcf2...) OK\n",
      "[49/99] Cr2W2Te8 (62bb754c4cb2...) OK\n",
      "[50/99] CrMo3S8 (644f7c1c85c7...) OK\n",
      "[51/99] WCr3Te8 (6523c349753c...) OK\n",
      "[52/99] AsBrTe (671e6de2497a...) OK\n",
      "[53/99] SeTeW (6e2a4c6f4f57...) OK\n",
      "[54/99] BiISe (70cbc0e44d36...) OK\n",
      "[55/99] HfZr3Se8 (70e7ab872359...) OK\n",
      "[56/99] Cr2Mo2S8 (72b286460831...) OK\n",
      "[57/99] STeW (75ee10091f43...) OK\n",
      "[58/99] S2Sn2 (7a8373382b33...) OK\n",
      "[59/99] BiClSe (7fe9c5cb910c...) OK\n",
      "[60/99] Hf2Zr2Se8 (81af2831dbb2...) OK\n",
      "[61/99] P2Sb2Te6 (82b85dfd7723...) OK\n",
      "[62/99] Ti2Zr2Se8 (846b50801a93...) OK\n",
      "[63/99] MoCr3Te8 (899032b4ad0c...) OK\n",
      "[64/99] STeW (916afba26723...) OK\n",
      "[65/99] MoCr3Se8 (961c37d6e527...) OK\n",
      "[66/99] BiClTe (968a6902b7f5...) OK\n",
      "[67/99] Cr2Mo2Te8 (988b11badabb...) OK\n",
      "[68/99] BiClS (99fd027b1d0b...) OK\n",
      "[69/99] WMo3S8 (9c2979187585...) OK\n",
      "[70/99] PbSe (a0dbdc6630fa...) OK\n",
      "[71/99] TiZr3Se8 (a148361e5e9a...) OK\n",
      "[72/99] Mo2W2Se8 (a1d716aad84d...) OK\n",
      "[73/99] CrMo3Se8 (a7233837cfe9...) OK\n",
      "[74/99] BiClSe (a80866a2c6b4...) OK\n",
      "[75/99] BiITe (a84d988e38ac...) OK\n",
      "[76/99] CrW3S8 (a9f87eba4b96...) OK\n",
      "[77/99]   (aa9a981d89aa...) OK\n",
      "[78/99] BiIS (acdcd16c0d76...) OK\n",
      "[79/99] AsIS (b13beafa16aa...) OK\n",
      "[80/99] ZrHf3Se8 (b8fb10416122...) OK\n",
      "[81/99] BiClTe (badda86cab42...) OK\n",
      "[82/99] Mo2W2Te8 (c04fc052f2ca...) OK\n",
      "[83/99] HfTi3Se8 (c55716558616...) OK\n",
      "[84/99] WCr3Se8 (c798e725e2fb...) OK\n",
      "[85/99] BiClS (c96ef4fc869c...) OK\n",
      "[86/99] Hf2Ti2Se8 (cce78d90e899...) OK\n",
      "[87/99] Bi2P2Te6 (cf7927ab6730...) OK\n",
      "[88/99] SeSn (d59c96fdfda1...) OK\n",
      "[89/99] ClSbTe (da5fd2bb47af...) OK\n",
      "[90/99] WCr3S8 (dc4259e69783...) OK\n",
      "[91/99] BiBrSe (de5756e4fbfa...) OK\n",
      "[92/99] ISbSe (df0019ec24b5...) OK\n",
      "[93/99] SnTe (e688959ea45b...) OK\n",
      "[94/99] GeTe (eadd37f03ca5...) OK\n",
      "[95/99] CrW3Te8 (eef072f845ce...) OK\n",
      "[96/99] BrSbTe (f1e78a09001d...) OK\n",
      "[97/99] BiBrTe (f4f45fcade85...) OK\n",
      "[98/99] ClSbSe (f705a30af945...) OK\n",
      "[99/99] AsClTe (fba4cc0df459...) OK\n",
      "\n",
      "==================================================\n",
      "Processed: 99 compounds\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BATCH PROCESS ALL COMPOUNDS\n",
    "# ============================================================\n",
    "\n",
    "all_results = {w: [] for w in WINDOWS}\n",
    "failed = []\n",
    "\n",
    "for idx, row in target.iterrows():\n",
    "    uid = row['uid']\n",
    "    formula = row['Formula']\n",
    "    alpha_R = row['alpha_R_max']\n",
    "    \n",
    "    if uid not in compound_dirs:\n",
    "        failed.append({'uid': uid, 'formula': formula, 'reason': 'no_folder'})\n",
    "        continue\n",
    "    \n",
    "    vasprun_path = compound_dirs[uid]['vasprun']\n",
    "    \n",
    "    print(f\"[{idx+1}/{len(target)}] {formula} ({uid[:12]}...)\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        for w in WINDOWS:\n",
    "            raw = extract_contributions(vasprun_path, w)\n",
    "            desc = compute_descriptors(raw)\n",
    "            desc['uid'] = uid\n",
    "            desc['Formula'] = formula\n",
    "            desc['alpha_R'] = alpha_R\n",
    "            desc['window'] = w\n",
    "            all_results[w].append(desc)\n",
    "        print(\"OK\")\n",
    "    except Exception as e:\n",
    "        failed.append({'uid': uid, 'formula': formula, 'reason': str(e)[:80]})\n",
    "        print(f\"FAILED: {str(e)[:60]}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Processed: {len(all_results[WINDOWS[0]])} compounds\")\n",
    "print(f\"Failed: {len(failed)}\")\n",
    "if failed:\n",
    "    print(\"Failed compounds:\")\n",
    "    for f in failed[:10]:\n",
    "        print(f\"  {f['formula']} ({f['uid'][:12]}): {f['reason']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 29 CSV files to C:\\Users\\AbCMS_Lab\\Desktop\\Keshav-DDP\\Weight-contribution\\contribution-model:\n",
      "  desc_ALL_multiwindow.csv (81.3 KB)\n",
      "  desc_ALL_w005.csv (10.8 KB)\n",
      "  desc_ALL_w01.csv (11.5 KB)\n",
      "  desc_ALL_w05.csv (37.6 KB)\n",
      "  desc_ALL_w10.csv (37.6 KB)\n",
      "  desc_A_w005.csv (5.6 KB)\n",
      "  desc_A_w01.csv (5.6 KB)\n",
      "  desc_A_w05.csv (8.4 KB)\n",
      "  desc_A_w10.csv (8.4 KB)\n",
      "  desc_B_w005.csv (5.6 KB)\n",
      "  desc_B_w01.csv (5.6 KB)\n",
      "  desc_B_w05.csv (8.3 KB)\n",
      "  desc_B_w10.csv (8.4 KB)\n",
      "  desc_C_w005.csv (5.6 KB)\n",
      "  desc_C_w01.csv (6.0 KB)\n",
      "  desc_C_w05.csv (12.4 KB)\n",
      "  desc_C_w10.csv (12.4 KB)\n",
      "  desc_D_w005.csv (6.4 KB)\n",
      "  desc_D_w01.csv (6.4 KB)\n",
      "  desc_D_w05.csv (11.9 KB)\n",
      "  desc_D_w10.csv (11.9 KB)\n",
      "  desc_E_w005.csv (5.2 KB)\n",
      "  desc_E_w01.csv (5.4 KB)\n",
      "  desc_E_w05.csv (8.5 KB)\n",
      "  desc_E_w10.csv (8.5 KB)\n",
      "  desc_F_w005.csv (6.4 KB)\n",
      "  desc_F_w01.csv (6.4 KB)\n",
      "  desc_F_w05.csv (12.0 KB)\n",
      "  desc_F_w10.csv (12.0 KB)\n",
      "\n",
      "E combo (0.5+1.0) shape: (99, 7)\n",
      "            uid  Formula  alpha_R  E_pfrac_VBM_w05  E_pfrac_CBM_w05  \\\n",
      "0  001e03f2c095     SSeW    3.288         0.204008         0.153851   \n",
      "1  03bcf7dcdaf2   Sn2Te2    4.804         0.639598         0.812826   \n",
      "2  04fdd7d1ec5c   ClSbTe    1.018         0.914850         0.915593   \n",
      "3  05a06afa3b20  WMo3Se8    1.643         0.173263         0.166401   \n",
      "4  0b7696e1f4c9  CrW3Se8    1.756         0.141816         0.108058   \n",
      "\n",
      "   E_pfrac_VBM_w10  E_pfrac_CBM_w10  \n",
      "0         0.224009         0.194420  \n",
      "1         0.678554         0.835895  \n",
      "2         0.884091         0.920193  \n",
      "3         0.229004         0.177661  \n",
      "4         0.181304         0.153414  \n",
      "\n",
      "Computing enhanced E variants with elemental properties...\n",
      "  desc_E_enhanced_w05.csv: (99, 22)\n",
      "  desc_E_enhanced_w10.csv: (99, 22)\n",
      "  desc_E_enhanced_w05_w10.csv: (99, 34)\n",
      "\n",
      "Total CSVs saved: 34\n",
      "  desc_ALL_multiwindow.csv\n",
      "  desc_ALL_w005.csv\n",
      "  desc_ALL_w01.csv\n",
      "  desc_ALL_w05.csv\n",
      "  desc_ALL_w10.csv\n",
      "  desc_A_w005.csv\n",
      "  desc_A_w01.csv\n",
      "  desc_A_w05.csv\n",
      "  desc_A_w10.csv\n",
      "  desc_B_w005.csv\n",
      "  desc_B_w01.csv\n",
      "  desc_B_w05.csv\n",
      "  desc_B_w10.csv\n",
      "  desc_C_w005.csv\n",
      "  desc_C_w01.csv\n",
      "  desc_C_w05.csv\n",
      "  desc_C_w10.csv\n",
      "  desc_D_w005.csv\n",
      "  desc_D_w01.csv\n",
      "  desc_D_w05.csv\n",
      "  desc_D_w10.csv\n",
      "  desc_E_enhanced_w05.csv\n",
      "  desc_E_enhanced_w05_w10.csv\n",
      "  desc_E_enhanced_w10.csv\n",
      "  desc_E_w005.csv\n",
      "  desc_E_w01.csv\n",
      "  desc_E_w05.csv\n",
      "  desc_E_w05_w10.csv\n",
      "  desc_E_w10.csv\n",
      "  desc_E_w10.csv\n",
      "  desc_F_w005.csv\n",
      "  desc_F_w01.csv\n",
      "  desc_F_w05.csv\n",
      "  desc_F_w10.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BUILD DATAFRAMES & SAVE CSVs\n",
    "# ============================================================\n",
    "\n",
    "# Descriptor type -> column prefixes\n",
    "type_cols = {\n",
    "    'A': [c for c in ['A_WM_VBM', 'A_WM_CBM']],\n",
    "    'B': [c for c in ['B_WMp_VBM', 'B_WMp_CBM']],\n",
    "    'C': [c for c in ['C_pfrac_h1_VBM', 'C_pfrac_h1_CBM', 'C_pfrac_h2_VBM', 'C_pfrac_h2_CBM']],\n",
    "    'D': [c for c in ['D_wm_h1_VBM', 'D_wm_h1_CBM', 'D_wm_h2_VBM', 'D_wm_h2_CBM']],\n",
    "    'E': [c for c in ['E_pfrac_VBM', 'E_pfrac_CBM']],\n",
    "    'F': [c for c in ['F_ph1_VBM', 'F_ph1_CBM', 'F_ph2_VBM', 'F_ph2_CBM']],\n",
    "}\n",
    "meta_cols = ['uid', 'Formula', 'alpha_R', 'heavy1_el', 'heavy2_el', 'heavy1_mass', 'heavy2_mass', 'n_elements']\n",
    "\n",
    "saved_csvs = []\n",
    "\n",
    "for w in WINDOWS:\n",
    "    df = pd.DataFrame(all_results[w])\n",
    "    w_str = str(w).replace('.', '')\n",
    "    \n",
    "    # Individual type CSVs\n",
    "    for t_name, t_cols in type_cols.items():\n",
    "        cols = meta_cols + t_cols\n",
    "        csv_name = f\"desc_{t_name}_w{w_str}.csv\"\n",
    "        csv_path = os.path.join(OUTPUT_DIR, csv_name)\n",
    "        df[cols].to_csv(csv_path, index=False)\n",
    "        saved_csvs.append(csv_name)\n",
    "    \n",
    "    # Combined: all types for this window\n",
    "    all_feature_cols = meta_cols + [c for cols in type_cols.values() for c in cols]\n",
    "    csv_name = f\"desc_ALL_w{w_str}.csv\"\n",
    "    csv_path = os.path.join(OUTPUT_DIR, csv_name)\n",
    "    df[all_feature_cols].to_csv(csv_path, index=False)\n",
    "    saved_csvs.append(csv_name)\n",
    "\n",
    "# Also: some useful combos across windows\n",
    "# Combo 1: Type A across all windows\n",
    "combo_rows = []\n",
    "for w in WINDOWS:\n",
    "    df_w = pd.DataFrame(all_results[w])\n",
    "    w_str = str(w).replace('.', '')\n",
    "    rename = {c: f\"{c}_w{w_str}\" for c in ['A_WM_VBM','A_WM_CBM','B_WMp_VBM','B_WMp_CBM',\n",
    "              'E_pfrac_VBM','E_pfrac_CBM','D_wm_h1_VBM','D_wm_h1_CBM',\n",
    "              'F_ph1_VBM','F_ph1_CBM']}\n",
    "    for old, new in rename.items():\n",
    "        if old in df_w.columns:\n",
    "            df_w[new] = df_w[old]\n",
    "\n",
    "# Multi-window combined\n",
    "dfs_w = {}\n",
    "for w in WINDOWS:\n",
    "    w_str = str(w).replace('.', '')\n",
    "    df_w = pd.DataFrame(all_results[w])\n",
    "    feature_cols_w = [c for cols in type_cols.values() for c in cols]\n",
    "    df_w = df_w[['uid', 'Formula', 'alpha_R'] + feature_cols_w]\n",
    "    df_w = df_w.rename(columns={c: f\"{c}_w{w_str}\" for c in feature_cols_w})\n",
    "    dfs_w[w] = df_w\n",
    "\n",
    "# Merge all windows\n",
    "df_multi = dfs_w[WINDOWS[0]]\n",
    "for w in WINDOWS[1:]:\n",
    "    df_multi = df_multi.merge(dfs_w[w].drop(columns=['Formula', 'alpha_R']), on='uid')\n",
    "\n",
    "csv_name = \"desc_ALL_multiwindow.csv\"\n",
    "csv_path = os.path.join(OUTPUT_DIR, csv_name)\n",
    "df_multi.to_csv(csv_path, index=False)\n",
    "saved_csvs.append(csv_name)\n",
    "\n",
    "print(f\"\\nSaved {len(saved_csvs)} CSV files to {OUTPUT_DIR}:\")\n",
    "for name in sorted(saved_csvs):\n",
    "    fpath = os.path.join(OUTPUT_DIR, name)\n",
    "    size = os.path.getsize(fpath) if os.path.exists(fpath) else 0\n",
    "    print(f\"  {name} ({size/1024:.1f} KB)\")\n",
    "\n",
    "# --- Extra: Type E combo CSVs (best performer) ---\n",
    "# E with 1.0 eV window\n",
    "if 1.0 in WINDOWS:\n",
    "    df_e10 = pd.DataFrame(all_results[1.0])\n",
    "    e10_path = os.path.join(OUTPUT_DIR, 'desc_E_w10.csv')\n",
    "    df_e10[meta_cols + ['E_pfrac_VBM', 'E_pfrac_CBM']].to_csv(e10_path, index=False)\n",
    "    saved_csvs.append('desc_E_w10.csv')\n",
    "\n",
    "# E with 0.5 + 1.0 combined (4 features)\n",
    "if 0.5 in WINDOWS and 1.0 in WINDOWS:\n",
    "    df_e05 = pd.DataFrame(all_results[0.5])[['uid', 'Formula', 'alpha_R', 'E_pfrac_VBM', 'E_pfrac_CBM']]\n",
    "    df_e05 = df_e05.rename(columns={'E_pfrac_VBM': 'E_pfrac_VBM_w05', 'E_pfrac_CBM': 'E_pfrac_CBM_w05'})\n",
    "    df_e10_slim = pd.DataFrame(all_results[1.0])[['uid', 'E_pfrac_VBM', 'E_pfrac_CBM']]\n",
    "    df_e10_slim = df_e10_slim.rename(columns={'E_pfrac_VBM': 'E_pfrac_VBM_w10', 'E_pfrac_CBM': 'E_pfrac_CBM_w10'})\n",
    "    df_e_combo = df_e05.merge(df_e10_slim, on='uid')\n",
    "    combo_path = os.path.join(OUTPUT_DIR, 'desc_E_w05_w10.csv')\n",
    "    df_e_combo.to_csv(combo_path, index=False)\n",
    "    saved_csvs.append('desc_E_w05_w10.csv')\n",
    "    print(f'\\nE combo (0.5+1.0) shape: {df_e_combo.shape}')\n",
    "    print(df_e_combo.head())\n",
    "\n",
    "# ============================================================\n",
    "# ENHANCED E VARIANTS: p_frac + elemental properties\n",
    "# ============================================================\n",
    "# Key elemental properties for SOC/Rashba:\n",
    "# - Z^4: SOC scales as Z^4 (THE most physically relevant)\n",
    "# - atomic_mass: heavier = more SOC\n",
    "# - atomic_radius: larger atoms = more diffuse orbitals\n",
    "# - electronegativity (X): controls charge transfer / dipole\n",
    "# - ionization_energy: relates to orbital energy levels\n",
    "#\n",
    "# For each compound, we compute:\n",
    "# - max_Z4: Z^4 of heaviest element\n",
    "# - weighted_Z4: sum(w_X * Z_X^4) at VBM/CBM\n",
    "# - max_mass: mass of heaviest element\n",
    "# - WM_VBM/CBM: sum(w_X * M_X)\n",
    "# - electronegativity_diff: max(X) - min(X) across elements\n",
    "# - weighted_radius: sum(w_X * r_X)\n",
    "\n",
    "from pymatgen.core.periodic_table import Element as Elem\n",
    "\n",
    "def compute_elemental_features(raw_contrib):\n",
    "    \"\"\"Compute elemental property descriptors from raw contributions.\"\"\"\n",
    "    feat = {}\n",
    "    elements = list(raw_contrib.keys())\n",
    "    \n",
    "    # Gather properties\n",
    "    props = {}\n",
    "    for el in elements:\n",
    "        e = Elem(el)\n",
    "        props[el] = {\n",
    "            'Z': e.Z,\n",
    "            'Z4': e.Z ** 4,\n",
    "            'mass': float(e.atomic_mass),\n",
    "            'radius': float(e.atomic_radius) if e.atomic_radius else 1.0,\n",
    "            'X': float(e.X) if e.X else 2.0,\n",
    "            'IE': float(e.ionization_energy) if e.ionization_energy else 8.0,\n",
    "            'vdw': float(e.van_der_waals_radius) if e.van_der_waals_radius else 1.5,\n",
    "        }\n",
    "    \n",
    "    # --- Raw elemental (no DOS weighting) ---\n",
    "    masses = [props[el]['mass'] for el in elements]\n",
    "    feat['max_mass'] = max(masses)\n",
    "    feat['max_Z'] = max(props[el]['Z'] for el in elements)\n",
    "    feat['max_Z4'] = max(props[el]['Z4'] for el in elements)\n",
    "    Xs = [props[el]['X'] for el in elements]\n",
    "    feat['X_diff'] = max(Xs) - min(Xs)  # electronegativity difference\n",
    "    feat['X_mean'] = np.mean(Xs)\n",
    "    radii = [props[el]['radius'] for el in elements]\n",
    "    feat['radius_diff'] = max(radii) - min(radii)\n",
    "    feat['radius_mean'] = np.mean(radii)\n",
    "    \n",
    "    # --- DOS-weighted elemental ---\n",
    "    for band in ['VBM', 'CBM']:\n",
    "        w_key = f'w_{band}'\n",
    "        p_key = f'p_{band}'\n",
    "        \n",
    "        # Weighted mass (WM)\n",
    "        feat[f'WM_{band}'] = sum(raw_contrib[el][w_key] * props[el]['mass'] for el in elements)\n",
    "        \n",
    "        # Weighted Z^4 (THE key one for SOC)\n",
    "        feat[f'WZ4_{band}'] = sum(raw_contrib[el][w_key] * props[el]['Z4'] for el in elements)\n",
    "        \n",
    "        # p-weighted Z^4\n",
    "        feat[f'pZ4_{band}'] = sum(raw_contrib[el][p_key] * props[el]['Z4'] for el in elements)\n",
    "        \n",
    "        # Weighted radius\n",
    "        feat[f'Wr_{band}'] = sum(raw_contrib[el][w_key] * props[el]['radius'] for el in elements)\n",
    "        \n",
    "        # Weighted electronegativity\n",
    "        feat[f'WX_{band}'] = sum(raw_contrib[el][w_key] * props[el]['X'] for el in elements)\n",
    "    \n",
    "    return feat\n",
    "\n",
    "# Recompute for 0.5 and 1.0 windows with elemental features\n",
    "print('\\nComputing enhanced E variants with elemental properties...')\n",
    "\n",
    "for w, w_str in [(0.5, 'w05'), (1.0, 'w10')]:\n",
    "    if w not in all_results or not all_results[w]:\n",
    "        continue\n",
    "    enhanced_rows = []\n",
    "    for entry in all_results[w]:\n",
    "        uid = entry['uid']\n",
    "        if uid not in compound_dirs:\n",
    "            continue\n",
    "        try:\n",
    "            raw = extract_contributions(compound_dirs[uid]['vasprun'], w)\n",
    "            elem_feat = compute_elemental_features(raw)\n",
    "            row = {\n",
    "                'uid': uid,\n",
    "                'Formula': entry['Formula'],\n",
    "                'alpha_R': entry['alpha_R'],\n",
    "                'E_pfrac_VBM': entry['E_pfrac_VBM'],\n",
    "                'E_pfrac_CBM': entry['E_pfrac_CBM'],\n",
    "            }\n",
    "            row.update(elem_feat)\n",
    "            enhanced_rows.append(row)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df_enh = pd.DataFrame(enhanced_rows)\n",
    "    csv_name = f'desc_E_enhanced_{w_str}.csv'\n",
    "    df_enh.to_csv(os.path.join(OUTPUT_DIR, csv_name), index=False)\n",
    "    saved_csvs.append(csv_name)\n",
    "    print(f'  {csv_name}: {df_enh.shape}')\n",
    "\n",
    "# Combined 0.5 + 1.0 enhanced\n",
    "if 0.5 in all_results and 1.0 in all_results:\n",
    "    df_05 = pd.read_csv(os.path.join(OUTPUT_DIR, 'desc_E_enhanced_w05.csv'))\n",
    "    df_10 = pd.read_csv(os.path.join(OUTPUT_DIR, 'desc_E_enhanced_w10.csv'))\n",
    "    # Rename to avoid collision\n",
    "    rename_05 = {c: f'{c}_w05' for c in df_05.columns if c not in ['uid','Formula','alpha_R','max_mass','max_Z','max_Z4','X_diff','X_mean','radius_diff','radius_mean']}\n",
    "    rename_10 = {c: f'{c}_w10' for c in df_10.columns if c not in ['uid','Formula','alpha_R','max_mass','max_Z','max_Z4','X_diff','X_mean','radius_diff','radius_mean']}\n",
    "    df_05r = df_05.rename(columns=rename_05)\n",
    "    df_10r = df_10.rename(columns=rename_10)\n",
    "    # Merge\n",
    "    shared = ['uid','Formula','alpha_R','max_mass','max_Z','max_Z4','X_diff','X_mean','radius_diff','radius_mean']\n",
    "    df_combo = df_05r.merge(df_10r.drop(columns=[c for c in shared if c in df_10r.columns and c != 'uid']), on='uid')\n",
    "    csv_name = 'desc_E_enhanced_w05_w10.csv'\n",
    "    df_combo.to_csv(os.path.join(OUTPUT_DIR, csv_name), index=False)\n",
    "    saved_csvs.append(csv_name)\n",
    "    print(f'  {csv_name}: {df_combo.shape}')\n",
    "\n",
    "print(f'\\nTotal CSVs saved: {len(saved_csvs)}')\n",
    "for name in sorted(saved_csvs):\n",
    "    print(f'  {name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (99, 26)\n",
      "\n",
      "First 5 rows:\n",
      "            uid  Formula  alpha_R heavy1_el heavy2_el  heavy1_mass  \\\n",
      "0  001e03f2c095     SSeW    3.288         W        Se       183.84   \n",
      "1  03bcf7dcdaf2   Sn2Te2    4.804        Te        Sn       127.60   \n",
      "2  04fdd7d1ec5c   ClSbTe    1.018        Te        Sb       127.60   \n",
      "3  05a06afa3b20  WMo3Se8    1.643         W        Mo       183.84   \n",
      "4  0b7696e1f4c9  CrW3Se8    1.756         W        Se       183.84   \n",
      "\n",
      "   heavy2_mass  n_elements  A_WM_VBM  A_WM_CBM  ...  D_wm_h1_VBM  D_wm_h1_CBM  \\\n",
      "0        78.96           3       0.0       0.0  ...          0.0          0.0   \n",
      "1       118.71           2       0.0       0.0  ...          0.0          0.0   \n",
      "2       121.76           3       0.0       0.0  ...          0.0          0.0   \n",
      "3        95.94           3       0.0       0.0  ...          0.0          0.0   \n",
      "4        78.96           3       0.0       0.0  ...          0.0          0.0   \n",
      "\n",
      "   D_wm_h2_VBM  D_wm_h2_CBM  E_pfrac_VBM  E_pfrac_CBM  F_ph1_VBM  F_ph1_CBM  \\\n",
      "0          0.0          0.0            0            0        0.0        0.0   \n",
      "1          0.0          0.0            0            0        0.0        0.0   \n",
      "2          0.0          0.0            0            0        0.0        0.0   \n",
      "3          0.0          0.0            0            0        0.0        0.0   \n",
      "4          0.0          0.0            0            0        0.0        0.0   \n",
      "\n",
      "   F_ph2_VBM  F_ph2_CBM  \n",
      "0        0.0        0.0  \n",
      "1        0.0        0.0  \n",
      "2        0.0        0.0  \n",
      "3        0.0        0.0  \n",
      "4        0.0        0.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Descriptor stats:\n",
      "       A_WM_VBM  A_WM_CBM  B_WMp_VBM  B_WMp_CBM  C_pfrac_h1_VBM  \\\n",
      "count      99.0      99.0       99.0       99.0            99.0   \n",
      "mean        0.0       0.0        0.0        0.0             0.0   \n",
      "std         0.0       0.0        0.0        0.0             0.0   \n",
      "min         0.0       0.0        0.0        0.0             0.0   \n",
      "25%         0.0       0.0        0.0        0.0             0.0   \n",
      "50%         0.0       0.0        0.0        0.0             0.0   \n",
      "75%         0.0       0.0        0.0        0.0             0.0   \n",
      "max         0.0       0.0        0.0        0.0             0.0   \n",
      "\n",
      "       C_pfrac_h1_CBM  C_pfrac_h2_VBM  C_pfrac_h2_CBM  D_wm_h1_VBM  \\\n",
      "count            99.0            99.0            99.0         99.0   \n",
      "mean              0.0             0.0             0.0          0.0   \n",
      "std               0.0             0.0             0.0          0.0   \n",
      "min               0.0             0.0             0.0          0.0   \n",
      "25%               0.0             0.0             0.0          0.0   \n",
      "50%               0.0             0.0             0.0          0.0   \n",
      "75%               0.0             0.0             0.0          0.0   \n",
      "max               0.0             0.0             0.0          0.0   \n",
      "\n",
      "       D_wm_h1_CBM  D_wm_h2_VBM  D_wm_h2_CBM  E_pfrac_VBM  E_pfrac_CBM  \\\n",
      "count         99.0         99.0         99.0         99.0         99.0   \n",
      "mean           0.0          0.0          0.0          0.0          0.0   \n",
      "std            0.0          0.0          0.0          0.0          0.0   \n",
      "min            0.0          0.0          0.0          0.0          0.0   \n",
      "25%            0.0          0.0          0.0          0.0          0.0   \n",
      "50%            0.0          0.0          0.0          0.0          0.0   \n",
      "75%            0.0          0.0          0.0          0.0          0.0   \n",
      "max            0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "       F_ph1_VBM  F_ph1_CBM  F_ph2_VBM  F_ph2_CBM  \n",
      "count       99.0       99.0       99.0       99.0  \n",
      "mean         0.0        0.0        0.0        0.0  \n",
      "std          0.0        0.0        0.0        0.0  \n",
      "min          0.0        0.0        0.0        0.0  \n",
      "25%          0.0        0.0        0.0        0.0  \n",
      "50%          0.0        0.0        0.0        0.0  \n",
      "75%          0.0        0.0        0.0        0.0  \n",
      "max          0.0        0.0        0.0        0.0  \n",
      "\n",
      "alpha_R range: [0.393, 4.804]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# QUICK SANITY CHECK\n",
    "# ============================================================\n",
    "df_check = pd.read_csv(os.path.join(OUTPUT_DIR, f\"desc_ALL_w005.csv\"))\n",
    "print(f\"Shape: {df_check.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_check.head())\n",
    "print(f\"\\nDescriptor stats:\")\n",
    "feature_cols = [c for c in df_check.columns if c.startswith(('A_','B_','C_','D_','E_','F_'))]\n",
    "print(df_check[feature_cols].describe().round(3))\n",
    "print(f\"\\nalpha_R range: [{df_check['alpha_R'].min():.3f}, {df_check['alpha_R'].max():.3f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
